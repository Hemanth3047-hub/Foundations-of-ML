{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991b67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required headers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956eaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintestSplit for dividing the data into train and test and returning those 2 data sets\n",
    "def trainTestSplit(dataFrame, testSize):\n",
    "    if isinstance(testSize, float):\n",
    "        testSize = round(testSize * len(dataFrame))\n",
    "    indices = dataFrame.index.tolist()\n",
    "    testIndices = random.sample(population = indices, k = testSize)\n",
    "    dataFrameTest = dataFrame.loc[testIndices]\n",
    "    dataFrameTrain = dataFrame.drop(testIndices)\n",
    "    return dataFrameTrain, dataFrameTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7628cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check whether all values of the respected attribute is same or not\n",
    "def checkPurity(data):\n",
    "    if len(np.unique(data.loc[:,data.columns[-1]])) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#functio used to classify data into uniqueClasses\n",
    "def classifyData(data):\n",
    "    uniqueClasses, uniqueClassesCounts = np.unique(data.loc[:,data.columns[-1]], return_counts = True)\n",
    "    return uniqueClasses[uniqueClassesCounts.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1d09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to obtain perfect splits based on the importance of attributes based on the previous attribute values\n",
    "def getPotentialSplits(data, randomAttributes):\n",
    "    potentialSplits = {}\n",
    "    _, columns = data.shape\n",
    "    columnsIndices = list(range(columns - 1))\n",
    "    if randomAttributes != None  and len(randomAttributes) <= len(columnsIndices):\n",
    "        columnsIndices = randomAttributes\n",
    "    for column in columnsIndices:\n",
    "        values = data.loc[:,data.columns[column]]\n",
    "        uniqueValues = np.unique(values)\n",
    "        if len(uniqueValues) == 1:\n",
    "            potentialSplits[column] = uniqueValues\n",
    "        else:\n",
    "            potentialSplits[column] = []\n",
    "            for i in range(len(uniqueValues)):\n",
    "                if i != 0:\n",
    "                    currentValue = uniqueValues[i]\n",
    "                    previousValue = uniqueValues[i - 1]\n",
    "                    potentialSplits[column].append((currentValue + previousValue) / 2)\n",
    "    return potentialSplits\n",
    "#function used to split data \n",
    "def splitData(data, splitColumn, splitValue):\n",
    "    splitColumnValues = data.loc[:,data.columns[splitColumn]]\n",
    "    return data[splitColumnValues <= splitValue], data[splitColumnValues > splitValue]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3b47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to calculate entropy value for each attribute present in the data\n",
    "def calculateEntropy(data):\n",
    "    _, uniqueClassesCounts = np.unique(data.loc[:,data.columns[-1]], return_counts = True)\n",
    "    probabilities = uniqueClassesCounts / uniqueClassesCounts.sum()\n",
    "    return sum(probabilities * -np.log2(probabilities))\n",
    "#function used to calculate overall entropy value for the whole data\n",
    "def calculateOverallEntropy(dataBelow, dataAbove):\n",
    "    pDataBelow = len(dataBelow) / (len(dataBelow) + len(dataAbove))\n",
    "    pDataAbove = len(dataAbove) / (len(dataBelow) + len(dataAbove))\n",
    "    return pDataBelow * calculateEntropy(dataBelow) + pDataAbove * calculateEntropy(dataAbove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f57468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to return the bestsplit column and value based upon the information gain and overall entropy\n",
    "def Best_split(data, potentialSplits, rand_S = None):\n",
    "    OE = 9999999999999\n",
    "    best_Split_Column = 0\n",
    "    best_Split_Value = 0\n",
    "    if rand_S != None:\n",
    "        for i in range(randomSplits):\n",
    "            randomSplitColumn = random.choice(list(potentialSplits))\n",
    "            randomSplitValue = random.choice(potentialSplits[randomSplitColumn])\n",
    "            dataBelow, dataAbove = splitData(data, randomSplitColumn, randomSplitValue)\n",
    "            currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
    "            if currentOverallEntropy <= OE:\n",
    "                OE = currentOverallEntropy\n",
    "                best_Split_Column = randomSplitColumn\n",
    "                best_Split_Value = randomSplitValue\n",
    "        \n",
    "    else:\n",
    "        for splitColumn in potentialSplits:\n",
    "            for splitValue in potentialSplits[splitColumn]:\n",
    "                dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
    "                currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
    "                if currentOverallEntropy <= OE:\n",
    "                    OE = currentOverallEntropy\n",
    "                    best_Split_Column = splitColumn\n",
    "                    best_Split_Value = splitValue\n",
    "        \n",
    "    return best_Split_Column, best_Split_Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08343ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to buildDecisionTree \n",
    "def buildDecisionTree(dataFrame, currentDepth = 0, minSampleSize = 2, maxDepth = 1000, randomAttributes = None, randomSplits = None):\n",
    "    global COLUMN_HEADERS\n",
    "    COLUMN_HEADERS = dataFrame.columns\n",
    "    if currentDepth == 0:\n",
    "        data = dataFrame.values\n",
    "        if randomAttributes != None and randomAttributes <= len(COLUMN_HEADERS) - 1:\n",
    "            randomAttributes = random.sample(population = list(range(len(COLUMN_HEADERS) - 1)), k = randomAttributes)\n",
    "        else:\n",
    "            randomAttributes = None\n",
    "    else:\n",
    "        data = dataFrame\n",
    "    if checkPurity(data) or len(data) < minSampleSize or currentDepth == maxDepth:\n",
    "        return classifyData(data)\n",
    "    else:\n",
    "        currentDepth += 1\n",
    "        potentialSplits = getPotentialSplits(data, randomAttributes)\n",
    "        splitColumn, splitValue = Best_split(data, potentialSplits, randomSplits)\n",
    "        dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
    "        if len(dataBelow) == 0 or len(dataAbove) == 0:\n",
    "            return classifyData(data)\n",
    "        else:\n",
    "            question = str(COLUMN_HEADERS[splitColumn]) + \" <= \" + str(splitValue)\n",
    "            decisionSubTree = {question: []}\n",
    "            yesAnswer = buildDecisionTree(dataBelow, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
    "            noAnswer = buildDecisionTree(dataAbove, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
    "            if yesAnswer == noAnswer:\n",
    "                decisionSubTree = yesAnswer\n",
    "            else:\n",
    "                decisionSubTree[question].append(yesAnswer)\n",
    "                decisionSubTree[question].append(noAnswer)\n",
    "            return decisionSubTree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16d977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySample(sample, decisionTree):\n",
    "    if not isinstance(decisionTree, dict):\n",
    "        return decisionTree\n",
    "    question = list(decisionTree.keys())[0]\n",
    "    attribute, value = question.split(\" <= \")\n",
    "    if sample[attribute] <= float(value):\n",
    "        answer = decisionTree[question][0]\n",
    "    else:\n",
    "        answer = decisionTree[question][1]\n",
    "    return classifySample(sample, answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b342f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to find predictions\n",
    "def decisionTreePredictions(dataFrame, decisionTree):\n",
    "    predictions = dataFrame.apply(classifySample, axis = 1, args = (decisionTree,))\n",
    "    return predictions\n",
    "#function used to calculate Accuracy\n",
    "def calculateAccuracy(predictedResults, category):\n",
    "    resultCorrect = predictedResults == category\n",
    "    return resultCorrect.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61cec4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used for bootstrapping of data\n",
    "def bootstrapping(train_df, n_bootstrap):\n",
    "    bootstrap_indices = np.random.randint(low=0, high=len(train_df), size=n_bootstrap)\n",
    "    df_bootstrapped = train_df.iloc[bootstrap_indices]\n",
    "    \n",
    "    return df_bootstrapped\n",
    "#Random_forest Implementation\n",
    "def RF_Implementation(train_df, n_trees, n_bootstrap, n_features, maxDepth):\n",
    "    forest = []\n",
    "    for i in range(n_trees):\n",
    "        df_bootstrapped = bootstrapping(train_df, n_bootstrap)\n",
    "        tree = buildDecisionTree(df_bootstrapped, maxDepth)\n",
    "        forest.append(tree)\n",
    "    \n",
    "    return forest\n",
    "#used for predicting the final value\n",
    "def RF_predict(test_df, forest):\n",
    "    df_predictions = {}\n",
    "    for i in range(len(forest)):\n",
    "        column_name = \"tree_{}\".format(i)\n",
    "        predictions = decisionTreePredictions(test_df,forest[i])\n",
    "        df_predictions[column_name] = predictions\n",
    "\n",
    "    df_predictions = pd.DataFrame(df_predictions)\n",
    "    RF_predict = df_predictions.mode(axis=1)[0]\n",
    "    \n",
    "    return RF_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37178ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data from the data.csv taking testSize=0.3(30% for test)\n",
    "file = open(\"data.csv\", \"r\")\n",
    "dataFrame = pd.read_csv(file, sep = \" \")\n",
    "dataFrameTrain, dataFrameTest = trainTestSplit(dataFrame, testSize = 0.3)\n",
    "RF_forest = RF_Implementation(dataFrameTrain, n_trees=4, n_bootstrap=800, n_features=2, maxDepth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "183e26b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9246376811594202\n"
     ]
    }
   ],
   "source": [
    "#finding the predictions and calculating accuracy\n",
    "predictions = RF_predict(dataFrameTest, RF_forest)\n",
    "accuracy = calculateAccuracy(predictions, dataFrameTest.loc[:,dataFrameTest.columns[-1]])\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260b0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7838ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6594515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
